CharTrans – Custom English-to-French Translator

CharTrans is a character-level English-to-French translation model built using TensorFlow/Keras. Unlike pretrained models, this model is trained from scratch on a parallel dataset of English and French sentences. It leverages a sequence-to-sequence (seq2seq) architecture with LSTM networks to generate French translations character by character.

Features

Character-level English→French translation

Seq2seq LSTM model with one-hot encoding

Streamlit web app for interactive translations

Fully trained on a custom parallel dataset

Demonstrates deep learning fundamentals for NLP

Installation

Clone the repository:

git clone <your-repo-url>
cd <repo-folder>


Create a virtual environment (optional but recommended):

python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows


Install dependencies:

pip install -r requirements.txt

Usage

Run the Streamlit app:

streamlit run app.py


Enter an English sentence in the text box, click Translate, and see the French translation generated by the model.

Training

Dataset: fra.txt (English-French sentence pairs)

Preprocessing: character-level one-hot encoding

Model: Seq2seq LSTM

Loss: Categorical Crossentropy

Optimizer: RMSprop

Latent dimension: 256

Training is done from scratch (CPU/GPU required)

File Structure
├── app.py                  # Streamlit frontend
├── model_data.pkl          # Trained model + token data
├── fra.txt                 # Dataset
├── requirements.txt        # Python dependencies
├── .gitignore              # Git ignore file
└── README.md               # Project documentation

Model Information

Name: CharTrans
Description: Custom character-level English→French translator trained using LSTM seq2seq networks with one-hot encoding. Generates French translations character by character and integrated with a Streamlit app for interactive use.

Dependencies

Python 3.10+

TensorFlow 2.x

NumPy

Streamlit

Pickle

Future Improvements

Incorporate attention mechanism for better translations

Train on larger datasets for improved accuracy

Implement word-level embeddings instead of character-level
